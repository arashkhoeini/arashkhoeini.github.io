<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.4" /><meta property="og:title" content="Self-supervision and Collapsing Solutions" /><meta name="author" content="Arash Khoeini" /><meta property="og:locale" content="en" /><meta name="description" content="Collapsing Solutions in Self-supervised Learning" /><meta property="og:description" content="Collapsing Solutions in Self-supervised Learning" /><link rel="canonical" href="https://arashkhoeini.github.io/posts/collapsing-solutions/" /><meta property="og:url" content="https://arashkhoeini.github.io/posts/collapsing-solutions/" /><meta property="og:site_name" content="Arash Khoeini" /><meta property="og:image" content="https://arashkhoeini.github.io/ssl-header.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-07T20:22:00-07:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://arashkhoeini.github.io/ssl-header.jpg" /><meta property="twitter:title" content="Self-supervision and Collapsing Solutions" /><meta name="twitter:site" content="@arashkhoeini" /><meta name="twitter:creator" content="@Arash Khoeini" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Arash Khoeini"},"dateModified":"2022-11-01T13:46:02-07:00","datePublished":"2022-07-07T20:22:00-07:00","description":"Collapsing Solutions in Self-supervised Learning","headline":"Self-supervision and Collapsing Solutions","image":"https://arashkhoeini.github.io/ssl-header.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://arashkhoeini.github.io/posts/collapsing-solutions/"},"url":"https://arashkhoeini.github.io/posts/collapsing-solutions/"}</script><title>Self-supervision and Collapsing Solutions | Arash Khoeini</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Arash Khoeini"><meta name="application-name" content="Arash Khoeini"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Arash Khoeini</a></div><div class="site-subtitle font-italic">Exploring the world through the lenses of science and art!</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/photo-blog/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>PHOTO BLOG</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/CV/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>CV</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/arashkhoeini" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/arashkhoeini" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['arash.khoeini','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Self-supervision and Collapsing Solutions</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Self-supervision and Collapsing Solutions</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Arash Khoeini </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Jul 7, 2022, 8:22 PM -0700" >Jul 7, 2022<i class="unloaded">2022-07-07T20:22:00-07:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Tue, Nov 1, 2022, 1:46 PM -0700" >Nov 1, 2022<i class="unloaded">2022-11-01T13:46:02-07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="971 words">5 min read</span></div></div><div class="post-content"><h1 id="collapsing-solutions-in-self-supervised-learning">Collapsing Solutions in Self-supervised Learning</h1><p><a href="/posts/self-supervision/">In the previous post I explained how self-supervised learning has been established as a decent method for unsupervised representation learning. I dicussed pre-text task learning, contrastive learning, and touched upon a few non-contrastive learning methods.</a></p><p>In this post, I aim to dig deeper into similarity learning. Similarity learning is a more general self-supervised learning approach and includes both contrastive and non-contrastive methods. In particular, I talk about collapsing solutions, what they are, and how different methods use different strategies to avoid these collapsing solutions.</p><h2 id="similarity-learning">Similarity Learning</h2><p>SSimilarity learning is a simple concept that most of the self-supervised methods are built based on. In similarity learning, a feature extractor f learns to map similar input close to each other in the representation space. This is very intuitive and could be looked at from various levels: two photos of a same cat but with different pose should be mapped close to each other in the representation space, two photos of different cats should be mapped relatively close to each other, compared to other classes like dogs. To learn such similarities, most of the current methods use some version of Siamese networks. Siamese networks are weight-sharing networks and this makes them a natural tool for comparing two or more inputs. In practive, Siamese network is just a fancy name for feeding two different inputs through the same network twice, and computing the desired loss function using two extracted representations. The two different input samples are usually two different augmented versions of the same sample.</p><p><img data-proofer-ignore data-src="/assets/img/collapsing-solutions.jpeg" alt="alt text" style="max-width: 90%" /></p><p><a href="https://scitechdaily.com/covid-19-has-triggered-a-global-financial-crisis-and-called-into-question-the-us-dollars-hegemony-whats-next/">image source</a></p><h2 id="collapsing-solutions">Collapsing Solutions</h2><p>There exists one major problem with similarity learning using Siamese networks and that’s called collapsing solutions! Forcing the network to map two different images very close to each other might end up in the network learning to cheat, and map EVERY input into a one same representation. This simply happens because our network learns to create a shortcut for minimizing loss: by just mapping everything to the same input.</p><p>Various strategies have been introduced in the self-supervised learning literature to avoid such collapsing shortcuts. We will discuss some of them briefly here.</p><h3 id="contrastive-learning">Contrastive Learning</h3><p>The core idea behind contrastive learning is to attract the positive sample pairs and repulse the negative sample pairs. The idea is straight forward: if we want to avoid our network to map every sample into a single point (to avoid finding a collapsing solution) we need to also define negative pairs and force our model to map them far apart. Different methods have different methodologies in order to define and use negative pairs. One well-known contrastive learning method is called SimCLR and it was introduced by Geoffrey Hinton team at Google Brain. SimCLR is short for Simple Contrasting LeaRning and its simplicity truly fits its name! In SimCLR, we create an augmentation for each data point in our batch. So we will have 2N data points for batch size N. Then for each input x_i, we take its augmentations as the positive sample for x_i and train the the network to minimize the distance between their latent representations. Meanwhile, we take all 2N-2 remaining samples as the negative samples for x_i and maximize the distance between their latent representation and x_i’s. This distance maximization between each input and its negative pairs is the key in avoiding collapsing solutions.</p><h3 id="clustering-methods">Clustering Methods</h3><p>Clustering methods use one distorted sample to compute ‘targets’ for the loss and another distorted version of the sample to predict these targets. This is followed by an alternate optimization (e.g. similar to k-means method) in <a href="https://arxiv.org/pdf/1807.05520.pdf">DeepCluster</a> or non-differentiable operators in <a href="https://arxiv.org/pdf/2006.09882.pdf">SwAV</a>.</p><h3 id="asymmetry-in-siamese-networks">Asymmetry In Siamese Networks</h3><p>When using Siamese networks for similarity learning, the main reason for collapsing is actually the symmetric architecture of the network. This symmetry exists because of the weight sharing in Siamese network. Although weight sharing is very intuitive for learning similarities, it is the driving force for collapsing. Therefore in another recent like of work new methods with asymmetric network architecture are introduced. In one method, named <a href="https://arxiv.org/pdf/2006.07733.pdf">BYOL (Bootstrap Your Own Latent representations)</a> two sub-networks of the Siamese network perform very different roles. Both of these sub-networks have a representation component and a projection component which projects the input image into its latent representations. But the top network (named as the online network) has one extra component compared to the bottom network (named as the target network). This extra component, which is called the prediction component, receives the latent representation of the online network as its input and tries to predict the latent representation of the target network. The other difference between these two networks is how their parameters are updated. The online network is trained through stochastic gradient descent. However, the target network is trained using the slow moving average of the online network. In another work, SimSiam, authors show that the only thing we need to prevent collapsing is a stop-grad operation. In SimSiam, the network architecture is modified to be asymmetric using a special ‘predictor’ network and the parameter updates are asymmetric such that the model parameters are only updated using one distorted version of the input, while the representations from another distorted version are used as a fixed target. Authors of SimSiam conclude that the asymmetry of the learning update, ‘stop-gradient’, is critical to preventing trivial solutions.</p><p>In this blog post I explained collapsing solutions and briefly introduced three lines of research targeting to avoid collapsing solutions. Please let me know in the comments if you know any other interesting method, or if there is any particular related paper that you would like me to summarize or explain in my Medium. This is actually what I think I am going to focus more on in this blog: to explain the core idea of the interesting papers I read with a simple language. Thank you for reading :)</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/tutorial/'>Tutorial</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >deep learning</a> <a href="/tags/self-supervised-learning/" class="post-tag no-text-decoration" >self-supervised learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Self-supervision and Collapsing Solutions - Arash Khoeini&url=https://arashkhoeini.github.io/posts/collapsing-solutions/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Self-supervision and Collapsing Solutions - Arash Khoeini&u=https://arashkhoeini.github.io/posts/collapsing-solutions/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Self-supervision and Collapsing Solutions - Arash Khoeini&url=https://arashkhoeini.github.io/posts/collapsing-solutions/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/garch/">Understanding GARCH Models, A Beginner-Friendly Guide with Python Implementation</a><li><a href="/posts/the-bitter-lession/">The Bitter Truth About AI; Why Human Ingenuity Often Loses to Computation</a><li><a href="/posts/FTTransformer/">FTTransformer; Transformer Architecture for Tabular Datasets</a><li><a href="/posts/self-supervision_for_tabular-data/">Self-Supervised Representation Learning for Tabular Datasets</a><li><a href="/posts/collapsing-solutions/">Self-supervision and Collapsing Solutions</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/artificial-intelligence/">artificial intelligence</a> <a class="post-tag" href="/tags/finance/">Finance</a> <a class="post-tag" href="/tags/self-supervised-learning/">self-supervised learning</a> <a class="post-tag" href="/tags/tabular-datasets/">tabular datasets</a> <a class="post-tag" href="/tags/calibration/">calibration</a> <a class="post-tag" href="/tags/computation/">computation</a> <a class="post-tag" href="/tags/machine-learning/">machine Learning</a> <a class="post-tag" href="/tags/self-supervised/">self-supervised</a> <a class="post-tag" href="/tags/transformers/">transformers</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/self-supervision_for_tabular-data/"><div class="card-body"> <span class="timeago small" >Nov 18, 2022<i class="unloaded">2022-11-18T17:30:00-08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Self-Supervised Representation Learning for Tabular Datasets</h3><div class="text-muted small"><p> Self-supervised Learning for Tabular Datasets Self-supervised learning aims to learn latent representations for unlabeled datasets. It has shown to be an effective representation learning method; ...</p></div></div></a></div><div class="card"> <a href="/posts/FTTransformer/"><div class="card-body"> <span class="timeago small" >Feb 2, 2024<i class="unloaded">2024-02-02T15:00:00-08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>FTTransformer; Transformer Architecture for Tabular Datasets</h3><div class="text-muted small"><p> Introduction If you follow my blog, you’ve probably noticed my keen interest in deep learning for tabular data. It’s not because I find tasks like predicting housing prices fascinating—I don’t! My...</p></div></div></a></div><div class="card"> <a href="/posts/what-is-calibration/"><div class="card-body"> <span class="timeago small" >Dec 9, 2020<i class="unloaded">2020-12-09T00:00:00-08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>What is a Calibrated Neural Network and why do we care?</h3><div class="text-muted small"><p> We love neural networks! We use them in our phones, our home speaker, our TVs, our cars and our almost everything! We like them when they are correct, and we ignore them when they are wrong. The me...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/self-supervision/" class="btn btn-outline-primary" prompt="Older"><p>Self-Supervised Learning</p></a> <a href="/posts/self-supervision_for_tabular-data/" class="btn btn-outline-primary" prompt="Newer"><p>Self-Supervised Representation Learning for Tabular Datasets</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://arashkhoeini.github.io/posts/collapsing-solutions/'; this.page.identifier = '/posts/collapsing-solutions/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://arashkhoeini-github-io.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (modeToggle !== null) { modeToggle.addEventListener('click', reloadDisqus); window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/username">Arash Khoeini</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/artificial-intelligence/">artificial intelligence</a> <a class="post-tag" href="/tags/finance/">Finance</a> <a class="post-tag" href="/tags/self-supervised-learning/">self supervised learning</a> <a class="post-tag" href="/tags/tabular-datasets/">tabular datasets</a> <a class="post-tag" href="/tags/calibration/">calibration</a> <a class="post-tag" href="/tags/computation/">computation</a> <a class="post-tag" href="/tags/machine-learning/">machine Learning</a> <a class="post-tag" href="/tags/self-supervised/">self supervised</a> <a class="post-tag" href="/tags/transformers/">transformers</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://arashkhoeini.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-MHEJ5WVV2C"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-MHEJ5WVV2C'); }); </script>
